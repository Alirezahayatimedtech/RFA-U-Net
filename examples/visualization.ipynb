{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RFA-U-Net Visualization\n",
        "\n",
        "This notebook demonstrates how to load the pre-trained RFA-U-Net model, run inference on a sample OCT image, and visualize the segmentation results using the `plot_boundaries` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from src.rfa_u_net import AttentionUNetViT, plot_boundaries, OCTDataset, val_test_transform\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    \"image_size\": 224,\n",
        "    \"hidden_dim\": 1024,\n",
        "    \"patch_size\": 16,\n",
        "    \"num_channels\": 3,\n",
        "    \"num_classes\": 2,\n",
        "    \"retfound_weights_path\": \"weights/rfa_unet_best.pth\"\n",
        "}\n",
        "\n",
        "# Load the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AttentionUNetViT(config).to(device)\n",
        "\n",
        "# Load pre-trained weights\n",
        "weights_path = config['retfound_weights_path']\n",
        "if os.path.exists(weights_path):\n",
        "    checkpoint = torch.load(weights_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "    print(f\"Loaded weights from {weights_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Weights file not found: {weights_path}. Please provide the correct path.\")\n",
        "model.eval()\n",
        "\n",
        "# Load a real test image and mask\n",
        "test_image_dir = \"/path/to/your/test/images\"\n",
        "test_mask_dir  = \"/path/to/your/test/masks\"\n",
        "dataset = OCTDataset(test_image_dir, test_mask_dir, config['image_size'], transform=val_test_transform)\n",
        "img, gt = dataset[0]  # first sample\n",
        "image = img.unsqueeze(0).to(device)\n",
        "mask  = gt.unsqueeze(0).to(device)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    predicted_mask = torch.sigmoid(output)\n",
        "\n",
        "# Visualization threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Visualize results\n",
        "plot_boundaries(image, mask, predicted_mask, threshold)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

